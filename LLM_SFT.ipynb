{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6202014-1c35-43e5-ba08-6d15aaa4b1d7",
   "metadata": {
    "id": "b6202014-1c35-43e5-ba08-6d15aaa4b1d7"
   },
   "source": [
    "# Проект обучение собственной LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76217e00-c245-4009-9dd1-45970527df2e",
   "metadata": {
    "id": "76217e00-c245-4009-9dd1-45970527df2e"
   },
   "source": [
    "***План проекта***\n",
    "\n",
    "В проекте необходимо реализовать pretrain и posttrain этапы обучения LLM.\n",
    "\n",
    "***Этапы проекта***\n",
    "\n",
    "1. Часть 1. Pretrain (предобучение). Цель: Научить модель генерировать осмысленный и стилистически корректный текст на основе корпуса русской классической литературы (JoannaBy/RussianNovels).\n",
    "   \n",
    "   1.1. Скачать данные из репозитория https://github.com/JoannaBy/RussianNovels/tree/master/corpus и упаковать их в один датасет.\n",
    "   \n",
    "   1.2. Провести препроцессинг данных:\n",
    "    - Очистить их от дубликатов.\n",
    "    - Очистить от предложений с буквами не из кириллицы.\n",
    "    - Обработайть повторяющуюся пунктуацию и т. д.\n",
    "    - Разбить на чанки поменьше, чтобы можно было добавить <bos> и <eos> токены в соответствии с обучаемой длиной контекста.\n",
    "   \n",
    "   1.3. Создать и обучить собственный токенизатор на полученных данных. Размер словаря выбрать небольшим.\n",
    "\n",
    "   1.4. Токенизация и формирование датасета.\n",
    "\n",
    "   1.5. Инициализация модели. Например, можно рассмотреть LlamaConfig с параметрами hidden_size=1024, intermediate_size=1536, num_hidden_layers=16, num_attention_heads=16, num_key_value_heads=8.\n",
    "   \n",
    "   1.6. Обучение с валидацией на промптах. Чтобы оценить качество, используем промпты. test_prompts = [\n",
    "    \"Все мысли, которые имеют огромные последствия\",\n",
    "    \"Сила войска зависит от его духа\",\n",
    "    \"Мысль о том, что он принес страдания\",\n",
    "    \"Человек сознает себя свободным\",\n",
    "    \"Что бы ни случилось, я всегда буду\",\n",
    "    \"Любовь мешает смерти\",\n",
    "    \"Нет, жизнь не кончена\",\n",
    "    \"Всякая мысль, даже самая простая\",\n",
    "    \"Война не любезность, а самое гадкое дело\",\n",
    "    \"Чтобы жить честно\"]\n",
    "\n",
    "    1.7. Сгенерировать ответы на запросы test_prompts.\n",
    "\n",
    "2. Часть 2. SFT (Supervised Fine-Tuning). Цель: Дообучить готовую предобученную модель на инструктивных данных, чтобы она могла корректно отвечать на вопросы на русском языке в формате «ассистент».\n",
    "\n",
    "   2.1. Загрузка базовой модели и токенизатора.\n",
    "\n",
    "   2.2. Подготовка инструктивного датасета, скачивание данных: d0rj/alpaca-cleaned-ru для обучения базовой модели.\n",
    "\n",
    "   2.3. Настройка SFT-обучения и обучение.\n",
    "\n",
    "   2.4. Оценка качества генерации. questions_rus = [\n",
    "    \"сколько планет в нашей солнечной системе?\",\n",
    "    \"расскажи стих\",\n",
    "    \"когда собирать крыжовник?\",\n",
    "    \"Как быстро выучить новый язык?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d1e18e-f618-4cdf-a7e4-ac42a1197fb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7768,
     "status": "ok",
     "timestamp": 1759075496568,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "f2d1e18e-f618-4cdf-a7e4-ac42a1197fb4",
    "outputId": "9d7228e6-9d4b-410b-e7e6-29d1376450b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/564.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/564.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Устанавливаем зависимости\n",
    "!pip install -q datasets transformers tokenizers accelerate trl sentencepiece torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e6426e-3740-484b-ab9e-425edee53e2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 22807,
     "status": "ok",
     "timestamp": 1759075521409,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "79e6426e-3740-484b-ab9e-425edee53e2b"
   },
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, PreTrainedTokenizerFast,\n",
    "    DataCollatorForLanguageModeling, LlamaConfig, LlamaForCausalLM, TrainerCallback)\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, processors\n",
    "from trl import SFTTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c976cf-bddc-4ddf-85a6-bc14e355cf5c",
   "metadata": {
    "id": "d8c976cf-bddc-4ddf-85a6-bc14e355cf5c"
   },
   "source": [
    "## Часть 1: Pretrain на русской литературе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a78090-79af-4bb1-89a2-533d04ac9bf8",
   "metadata": {
    "id": "74a78090-79af-4bb1-89a2-533d04ac9bf8"
   },
   "source": [
    "Pretrain (предобучение) — сделаем первый этап обучения языковой модели, когда она учится общей структуре языка и стилистике на конкретной информации (произведения Русской литературы): грамматике, стилю, последовательности слов, логике повествования и т.д. Цель: научить модель генерировать стилистически и грамматически правдоподобный текст в духе этих произведений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424361aa-e8e2-4775-989c-dbd1c25b1258",
   "metadata": {
    "id": "424361aa-e8e2-4775-989c-dbd1c25b1258"
   },
   "source": [
    "### Скачивание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e20d7-530b-41e1-830d-2b74e721d798",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6010,
     "status": "ok",
     "timestamp": 1759049080970,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "844e20d7-530b-41e1-830d-2b74e721d798",
    "outputId": "28ee1b41-74e2-41a7-f5c9-6fb689c4c788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RussianNovels'...\n",
      "remote: Enumerating objects: 119, done.\u001b[K\n",
      "remote: Total 119 (delta 0), reused 0 (delta 0), pack-reused 119 (from 1)\u001b[K\n",
      "Receiving objects: 100% (119/119), 21.67 MiB | 5.92 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n",
      "Загружено 108 произведений.\n"
     ]
    }
   ],
   "source": [
    "# Скачиваем данные с репозитория\n",
    "!git clone https://github.com/JoannaBy/RussianNovels.git\n",
    "\n",
    "# Собираем все .txt файлы\n",
    "corpus_dir = Path(\"RussianNovels/corpus\")\n",
    "texts = []\n",
    "for file_path in corpus_dir.glob(\"*.txt\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts.append(f.read())\n",
    "\n",
    "print(f\"Загружено {len(texts)} произведений.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b48851-b696-4ab8-828a-788465d8a771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1759049087054,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "33b48851-b696-4ab8-828a-788465d8a771",
    "outputId": "d54a0ab8-3f44-4d21-8234-0359d9791753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество символов: 45348575\n",
      "Средняя длина текста: 419894 символов\n",
      "Примерный размер датасета в токенах: 6,942,495\n",
      "Примерный размер в MB: 76.4 MB\n",
      "Мин. длина: 32,578 символов\n",
      "Макс. длина: 3,075,836 символов\n",
      "Медиана: 300,394 символов\n",
      "Общее количество слов: 6,942,495\n",
      "Среднее количество слов: 64,282\n",
      "Рекомендуемое количество эпох: 1.4\n"
     ]
    }
   ],
   "source": [
    "# Статистика по текстам\n",
    "print(f\"Общее количество символов: {sum(len(text) for text in texts)}\")\n",
    "print(f\"Средняя длина текста: {sum(len(text) for text in texts) / len(texts):.0f} символов\")\n",
    "\n",
    "# Статистика для анализа\n",
    "def pretraining_analysis(texts):\n",
    "    total_tokens = sum(len(text.split()) for text in texts)\n",
    "    print(f\"Примерный размер датасета в токенах: {total_tokens:,}\")\n",
    "    print(f\"Примерный размер в MB: {sum(len(text.encode('utf-8')) for text in texts) / 1024 / 1024:.1f} MB\")\n",
    "    text_lengths = [len(text) for text in texts]\n",
    "    word_counts = [len(text.split()) for text in texts]\n",
    "    print(f\"Мин. длина: {min(text_lengths):,} символов\")\n",
    "    print(f\"Макс. длина: {max(text_lengths):,} символов\")\n",
    "    print(f\"Медиана: {sorted(text_lengths)[len(text_lengths)//2]:,} символов\")\n",
    "    print(f\"Общее количество слов: {sum(word_counts):,}\")\n",
    "    print(f\"Среднее количество слов: {sum(word_counts)/len(word_counts):,.0f}\")\n",
    "\n",
    "    # Оценка для обучения\n",
    "    if total_tokens > 1_000_000:\n",
    "        epochs_estimation = min(3, 10_000_000 / total_tokens)\n",
    "        print(f\"Рекомендуемое количество эпох: {epochs_estimation:.1f}\")\n",
    "\n",
    "    return total_tokens\n",
    "\n",
    "total_tokens = pretraining_analysis(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a6cf2-803b-4d0c-a727-a443ed0ba432",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759049093999,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "869a6cf2-803b-4d0c-a727-a443ed0ba432",
    "outputId": "9f1903cf-5d19-4aa7-946a-e604b103eb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТ ИЗДАТЕЛЯ\n",
      "\n",
      "  \n",
      "   Взявшись хлопотать об издании Повестей И. П. Белкина, предлагаемых ныне публике, мы желали к оным присовокупить хотя краткое жизнеописание покойного автора и тем отчасти удовлетворить справедливому любопытству любителей отечественной словесности. Для сего обратились было мы к Марь\n"
     ]
    }
   ],
   "source": [
    "# Просмотрим первые 300 символов у первого сборника\n",
    "print(texts[0][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154bf3a-68ba-4f9d-b249-528a0bfac420",
   "metadata": {
    "id": "4154bf3a-68ba-4f9d-b249-528a0bfac420"
   },
   "source": [
    "***Вывод загрузка данных***\n",
    "\n",
    "Количество текстов 108.\n",
    "\n",
    "Наблюдается разброс длины мин и мах, датасет не равномерный.\n",
    "\n",
    "Есть очень длинные произведения и очень короткие, что нормально для такого сборника."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b74db-504b-4062-90d6-3a75164d5625",
   "metadata": {
    "id": "944b74db-504b-4062-90d6-3a75164d5625"
   },
   "source": [
    "### Предпроцессинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6dec0-25fc-41ce-8f80-9ff46d0d1fe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4096,
     "status": "ok",
     "timestamp": 1759049106399,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "24b6dec0-25fc-41ce-8f80-9ff46d0d1fe6",
    "outputId": "8fd01e93-9bc0-4e5e-cdf8-e0afe3bda7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После очистки: 107 уникальных текстов.\n"
     ]
    }
   ],
   "source": [
    "# Очищаем и обрабатываем текст, удаляем дубликаты если есть\n",
    "def clean_text(text):\n",
    "    lines = text.split('\\n')\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        # Оставляем только строки с кириллицей\n",
    "        if re.search(r'[а-яА-ЯёЁ]', line):\n",
    "            # Удаляем недопустимые символы\n",
    "            line = re.sub(r'[^а-яА-ЯёЁ\\s.,!?;:—–\\-\\\"\\'()\\[\\]0-9]', ' ', line)\n",
    "            line = re.sub(r'\\s+', ' ', line).strip()\n",
    "            if len(line) > 20:\n",
    "                cleaned.append(line)\n",
    "    return ' '.join(cleaned)\n",
    "\n",
    "cleaned_texts = [clean_text(t) for t in texts if t.strip()]\n",
    "cleaned_texts = [t for t in cleaned_texts if len(t) > 100]\n",
    "\n",
    "# Удаляем дубликаты\n",
    "cleaned_texts = list(set(cleaned_texts))\n",
    "print(f\"После очистки: {len(cleaned_texts)} уникальных текстов.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2f062-f04d-418b-bf08-8c48fe2af0d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1759049109850,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "bda2f062-f04d-418b-bf08-8c48fe2af0d3",
    "outputId": "e9c37689-779b-4610-b1c3-9f0067b8d25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены: Train: 101, Val: 6\n"
     ]
    }
   ],
   "source": [
    "# Разделение на train/val - 5% на валидацию\n",
    "train_texts, val_texts = train_test_split(\n",
    "    cleaned_texts,\n",
    "    test_size=0.05,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Данные разделены: Train: {len(train_texts)}, Val: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799f61c-c4c0-4922-ab98-53cd2533ceaf",
   "metadata": {
    "id": "5799f61c-c4c0-4922-ab98-53cd2533ceaf"
   },
   "source": [
    "***Вывод***\n",
    "\n",
    "Чанки сделаем после токенизации, чтобы была гарантия что каждый чанк будет не длинее 512 токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424bf75-100c-4c2c-b220-357a636100fb",
   "metadata": {
    "id": "6424bf75-100c-4c2c-b220-357a636100fb"
   },
   "source": [
    "### Создание и обучение токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf08464-5412-4eb3-a322-9f6125cb0c74",
   "metadata": {
    "id": "bbf08464-5412-4eb3-a322-9f6125cb0c74"
   },
   "outputs": [],
   "source": [
    "# Сохраняем корпус для токенизатора\n",
    "with open(\"train_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for t in train_texts:\n",
    "        f.write(t + \"\\n\")\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=3000,\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"]\n",
    ")\n",
    "\n",
    "tokenizer.train([\"train_corpus.txt\"], trainer)\n",
    "tokenizer.save(\"custom_tokenizer.json\")\n",
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"custom_tokenizer.json\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc2211-b165-42d6-99ea-83835f8e8a54",
   "metadata": {
    "id": "3fbc2211-b165-42d6-99ea-83835f8e8a54"
   },
   "source": [
    "### Токенизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb288b87-20e3-49f3-8bd2-c7bc3e0c433d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33373,
     "status": "ok",
     "timestamp": 1759049164442,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "cb288b87-20e3-49f3-8bd2-c7bc3e0c433d",
    "outputId": "debe1efa-ec39-45ed-819d-69cbacc1a752"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing train: 100%|██████████| 101/101 [00:28<00:00,  3.51it/s]\n",
      "Tokenizing val: 100%|██████████| 6/6 [00:01<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Токенизация и чанкование в токенном пространстве\n",
    "def tokenize_and_chunk(texts, tokenizer, block_size=512, desc=\"Processing\"):\n",
    "    \"\"\"\n",
    "    Токенизирует список текстов и разбивает на чанки фиксированной длины.\n",
    "    Возвращает список списков токенов (input_ids).\n",
    "    \"\"\"\n",
    "    all_input_ids = []\n",
    "\n",
    "    # Собираем все токены с <eos> между документами\n",
    "    for text in tqdm(texts, desc=desc):\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "        all_input_ids.extend(tokens)\n",
    "        all_input_ids.append(tokenizer.eos_token_id)\n",
    "\n",
    "    # Чанкуем на блоки фиксированной длины\n",
    "    chunks = []\n",
    "    for i in range(0, len(all_input_ids), block_size):\n",
    "        chunk = all_input_ids[i:i + block_size]\n",
    "        if len(chunk) == block_size:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Применяем\n",
    "train_chunks_ids = tokenize_and_chunk(train_texts, hf_tokenizer, block_size=512, desc=\"Tokenizing train\")\n",
    "val_chunks_ids = tokenize_and_chunk(val_texts, hf_tokenizer, block_size=512, desc=\"Tokenizing val\")\n",
    "\n",
    "# Создаём Dataset напрямую из input_ids\n",
    "train_dataset = Dataset.from_dict({\"input_ids\": train_chunks_ids})\n",
    "val_dataset = Dataset.from_dict({\"input_ids\": val_chunks_ids})\n",
    "\n",
    "full_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a70672-ae27-4dbb-8cf9-8ba42b43e7d6",
   "metadata": {
    "id": "77a70672-ae27-4dbb-8cf9-8ba42b43e7d6"
   },
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64135cbd-6540-44fe-a013-027d72f53102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5520,
     "status": "ok",
     "timestamp": 1759049175315,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "64135cbd-6540-44fe-a013-027d72f53102",
    "outputId": "485947fe-6de4-478b-d04c-59f467df7e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель создана. Параметров: 191,398,912\n"
     ]
    }
   ],
   "source": [
    "# Создаем Confi\n",
    "config = LlamaConfig(\n",
    "    vocab_sigze=hf_tokenizer.vocab_size,        # ~3000\n",
    "    hidden_size=1024,                          # d_model\n",
    "    intermediate_size=1536,                    # FFN hidden\n",
    "    num_hidden_layers=16,                      # количество блоков\n",
    "    num_attention_heads=16,\n",
    "    num_key_value_heads=8,                     # для Grouped-Query Attention\n",
    "    max_position_embeddings=512,               # длина контекста\n",
    "    bos_token_id=hf_tokenizer.bos_token_id,\n",
    "    eos_token_id=hf_tokenizer.eos_token_id,\n",
    "    pad_token_id=hf_tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM(config)\n",
    "print(f\"Модель создана. Параметров: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1193602-74cb-4deb-8b0f-26bfc02130e8",
   "metadata": {
    "id": "d1193602-74cb-4deb-8b0f-26bfc02130e8"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ade18f-e9fe-4b15-81a9-0aeb9c6b1e12",
   "metadata": {
    "id": "08ade18f-e9fe-4b15-81a9-0aeb9c6b1e12"
   },
   "outputs": [],
   "source": [
    "# Создадим кастомный коллбэк (callback) для отслеживания прогресса обучения модели в процессе работы Trainer\n",
    "class GenCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, prompts, model, device):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompts = prompts\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 200 == 0 and state.global_step > 0:\n",
    "            print(f\"\\n=== Шаг {state.global_step} ===\")\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for p in self.prompts[:2]:\n",
    "                    inp = self.tokenizer(\n",
    "                        p,\n",
    "                        return_tensors=\"pt\",\n",
    "                        return_token_type_ids=False\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    out = self.model.generate(\n",
    "                        **inp,\n",
    "                        max_new_tokens=50,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.85,\n",
    "                        pad_token_id=self.tokenizer.pad_token_id\n",
    "                    )\n",
    "                    print(self.tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "            self.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uyz51wflgVXN",
   "metadata": {
    "id": "uyz51wflgVXN"
   },
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"Все мысли, которые имеют огромные последствия\",\n",
    "    \"Сила войска зависит от его духа\",\n",
    "    \"Мысль о том, что он принес страдания\",\n",
    "    \"Человек сознает себя свободным\",\n",
    "    \"Что бы ни случилось, я всегда буду\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2ed28-c6dd-4f19-a065-483aab5b1663",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "executionInfo": {
     "elapsed": 2505875,
     "status": "ok",
     "timestamp": 1759053682269,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "cab2ed28-c6dd-4f19-a065-483aab5b1663",
    "outputId": "4cecad48-56cc-4f48-b40a-1ee6f054100d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='394' max='394' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [394/394 41:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.361200</td>\n",
       "      <td>5.195405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Шаг 200 ===\n",
      "Все мысли , которые име ют огром ные послед ствия . -- Я при се ть , -- сказал он , -- продолжал он . \" Вот я , вот мне не вы все равно . -- Я от этого не то , что и не могу т вам . И он за шел , от чего он по кор\n",
      "Си ла вой ска зави си т от его ду ха н ло , о з вала в пе рил ( в при не , в про ще нной , а ме че , то что - то есть , он , не мог бы это , хотя ему , он стал в гости нее о нем , пере дать ее\n",
      "Pretrain модель сохранена\n"
     ]
    }
   ],
   "source": [
    "# Переводим на устройство\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Обучение\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pretrain_results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=32,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_dataset[\"train\"],\n",
    "    eval_dataset=full_dataset[\"validation\"],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=hf_tokenizer, mlm=False),\n",
    "    callbacks=[GenCallback(hf_tokenizer, test_prompts, model, device)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Сохранение чекпоинта\n",
    "model.save_pretrained(\"./checkpoints/pretrain_model\")\n",
    "hf_tokenizer.save_pretrained(\"./checkpoints/pretrain_tokenizer\")\n",
    "print(\"Pretrain модель сохранена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b7cd1-3c93-45f5-b516-b445eb7a8dba",
   "metadata": {
    "id": "145b7cd1-3c93-45f5-b516-b445eb7a8dba"
   },
   "source": [
    "### Генерация ответов на запросы test_prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa123f-d427-4007-9305-f0d5e005dc25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5333,
     "status": "ok",
     "timestamp": 1759053746518,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "91aa123f-d427-4007-9305-f0d5e005dc25",
    "outputId": "c4252dac-1350-40f1-f037-6b2210a8b732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Все мысли, которые имеют огромные последствия\n",
      "Output: Все мысли , которые име ют огром ные послед ствия себя в ка ком , но она у меня на себя к нему с нею , про мол чала ю , как она как то не может , и когда он уже не совсем не известно . Да и ты не могу , чтобы все еще не только , но\n",
      "--------------------------------------------------\n",
      "Input: Сила войска зависит от его духа\n",
      "Output: Си ла вой ска зави си т от его ду ха , при па жа ются про шел и на ка ты , за га ле ны - то и , - говорил Самгин . На м ма ты , и , она за с ал - и по тя не ты , - сказал он . Т ри лась ,\n",
      "--------------------------------------------------\n",
      "Input: Мысль о том, что он принес страдания\n",
      "Output: Мы с ль о том , что он при нес стра дания . Вы - с , вы ря ди в , - у меня не было по ку ще : - Это очень у ез д , в том , что я в с ала , или я до ле ра . - Ну , это ты ? - думал он\n",
      "--------------------------------------------------\n",
      "Input: Человек сознает себя свободным\n",
      "Output: Че лове к со знает себя свобо д ным , - как они при жи вался со бира ть но ма , который у слышал и от ры в . - По ро жи на , - сказал он , - сказал Д он , - и с о - - а - да й и - то ?\n",
      "--------------------------------------------------\n",
      "Input: Что бы ни случилось, я всегда буду\n",
      "Output: Что бы ни случилось , я всегда буду не было , что я вам не от ка ря ть , когда она я не ве ру , но , и она , кажется , я не было меня ; кажется , что такое и на него , но я не по чи м . Но я сейчас ,\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Загружаем можель из checkpoints\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./checkpoints/pretrain_model\", device_map=\"auto\")\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(\"./checkpoints/pretrain_tokenizer\")\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = hf_tokenizer.eos_token\n",
    "\n",
    "# Переводим модель в режим оценки\n",
    "model.eval()\n",
    "for prompt in test_prompts:\n",
    "    inputs = hf_tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        pad_token_id=hf_tokenizer.pad_token_id\n",
    "    )\n",
    "    print(\"Input:\", prompt)\n",
    "    print(\"Output:\", hf_tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c9ad2-1871-45a9-b01b-c33d8305bd67",
   "metadata": {},
   "source": [
    "***Вывод по Этапу 1 (Pretrain — Предобучение)***\n",
    "\n",
    "На первом этапе модель была обучена только на корпусе русской классической литературы. Результаты генерации на промптах показывают, что модель:\n",
    "\n",
    "Успешно усвоила стилистику и синтаксис классического русского языка — тексты содержат сложные предложения, характерные для XIX века, с использованием архаичных или литературных оборотов.\n",
    "\n",
    "Генерирует осмысленный, но не всегда логически завершённый текст — видны попытки продолжить мысль, но часто без чёткой структуры, с обрывками фраз и неполными предложениями (например: «...и когда он уже не совсем не известно. Да и ты не могу, чтобы все еще не только, но»).\n",
    "Имеет проблемы с грамматикой и пунктуацией — наблюдаются лишние пробелы, разбитые слова («Си ла вой ска зави си т от его ду ха»), некорректное использование запятых и тире.\n",
    "Не понимает контекст запроса как задачу — она не отвечает на промпт, а просто «продолжает» его как часть художественного текста, что соответствует её тренировочному корпусу.\n",
    "\n",
    "Улучшение модели: Улучшить качество препроцессинга на этапе Pretrain, например очистка от артефактов и повторяющейся пунктуации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbaf86-fa42-436b-a33b-db5900270b4a",
   "metadata": {
    "id": "26fbaf86-fa42-436b-a33b-db5900270b4a"
   },
   "source": [
    "## Часть 2: SFT на инструктивных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbc986-dc27-4073-b951-6c437657ed5c",
   "metadata": {
    "id": "63cbc986-dc27-4073-b951-6c437657ed5c"
   },
   "source": [
    "SFT = Supervised Fine-Tuning — добавим этап дообучения уже предобученной модели на парах «инструкция → ответ».\n",
    "\n",
    "Возьмем готовую модель Qwen2.5-0.5B, которая уже прошла полноценное предобучение на огромных данных (включая русский язык).\n",
    "\n",
    "Дообучим ее на датасете d0rj/alpaca-cleaned-ru, где есть примеры:\n",
    "\n",
    "Цель SFT — научить модель следовать инструкциям и генерировать полезные, связные ответы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc8d1c-2459-44ca-ba8e-71c6d5c09f68",
   "metadata": {
    "id": "51cc8d1c-2459-44ca-ba8e-71c6d5c09f68"
   },
   "source": [
    "### Загрузка базовой модели и токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "HxzPgPHnEwPN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389,
     "referenced_widgets": [
      "6c8931bd168545e9ba2de5660893ac41",
      "928c324e2943424ebb8c25433003ff80",
      "5d84eb39d0e940438d124233a9631b6a",
      "ad81401d0fcf45988fbc15ec67a45499",
      "91ca0fb07e8c46da95f8ea21411c5ca9",
      "25f4ff0ddfdd4e5bac7a46be49490157",
      "76b34e56a8054d0f82b400619764cc68",
      "9c13b46a25b54152b184422839b9c5c3",
      "4621142a923146c9a4cac28db3775c1b",
      "0514108892da49beb491307911340106",
      "addc73f71060444d89fdc879ce2f96a6",
      "454b8c1d0e0c4d94a0e18f0204d840e2",
      "10229428b81941c6806de6e954604a83",
      "63b223c222cc4f81b2154d7c701a5756",
      "78f4498cc03b41f5b5e920657559848d",
      "5dcc9474cba44d7a98c52c0ebd8aadae",
      "a4eaf86303e64fadba9a8b5e50732120",
      "4581dd5c784d460092f81a02d4a012ac",
      "8fad05d83b04454c9550133881bb025c",
      "54feaa0aa81b401e98ea0f242d25c810",
      "8a42074dfddf47008147c41a2ef34c06",
      "717ff02269d54103a7ecee48a4457f55",
      "9436e720bdf145cbbbeba905cca109f2",
      "80395b8128f442418167951e96b2aa78",
      "2e08df1dc90f4e92841777bd3e8ff549",
      "53c1e1914ba943c7b6d4da3d37bbb2cf",
      "c5a765dd0f9e481e94cc7ac9d604096c",
      "cc0ccbb49a9245b9b37e5a07d2b6a516",
      "661d4b78141b4e57be231bdb3dad2d76",
      "361e8de148ae44d4bf46a48dc2be89ac",
      "7839e6f93fea4cf1ab5c2738635d3cf4",
      "0c1d6f8909ea48389488891861085ebd",
      "efdebe09b1894f869d256cdcfd88c738",
      "93b7b5a8becd459d9dbe2ba4f2ec3538",
      "cc8e8524e9544937924cf17b3e77ee4b",
      "c88eb742c1054b0fb8f12c11e503b088",
      "f31fdc9ccc1d4296a5f980ea05b2f68d",
      "b9ac1890b5894116ab3011ccb582560a",
      "a7dd3505fbf34415a26836995ddc6f1d",
      "1403ec3fa00d41208c652673db1e5e86",
      "fe3a0dfe3ada47d0bd664bd81bb62e07",
      "cc8c03b3ae864d9e8348ef57650b678d",
      "394b31f059514041a203f5a63ec20d0e",
      "d6d83858bcbf47318da1dee0e7f649f8",
      "08816bff273e445e9626c91d599044fa",
      "583d4c9637d544f895e62d1b642737ca",
      "41d0e384dc3d4381aa0fd12c7f28ad6f",
      "ad4647f8e96f4068ba9f39f16dfe2254",
      "fa61055d23a642de889747477c3f4bdd",
      "5bbd125c835c4180b3b16ce50ad3694b",
      "dbbe22449ed345a1b119b1d82d4d6be5",
      "f236df881b4448ada397235d197adf90",
      "f0df3977adb74bfdafcf08c4985d7e71",
      "6913e68b7a274ed0b39a0dbd2cfd5fa5",
      "38f4cf8370d24b8f82e5a2c184d95d75",
      "e45ecd6af8b44638a25a422f35206f08",
      "b75ad604bc164a768d661a69b84f3ff1",
      "e5203bcbf4854643ba785c1e5e909907",
      "77b849b6e5584465934186023968a419",
      "80746521fa974082a2f5f49506d0aeb2",
      "1d77328f509a4fb8b13c86ee22b98609",
      "36dd1c5c47b7447b8f62307ad7abbad6",
      "4c112553072740969c236a21a11b1815",
      "48927410aeba4cc9a4af1d1733ca2792",
      "6ab37a45c43c4a6f9d05b791f952b276",
      "7e5c4410a5a449aaba482dd069aa1e97",
      "2016db24575549abae9411304ffb9a0a",
      "7c14c442f1f84f48b75f8e9c7f7d2090",
      "70f7bf84a16a4d20bff4c08519e7bd52",
      "23934e1851e946838bc4af9467567538",
      "d5c51c1cb3a94eeeba49b3e2e089efe0",
      "4bc60f037d194c298b467b2f664951d6",
      "b36cb4ee96e3435fb2a0840b817a08a7",
      "64a24e3af503498da873e8a98f98acad",
      "6e84771cd6354a9fa52379a3b3d1b1ef",
      "547cb61db96249769b5d0fa5a0bfcc17",
      "feb870807606471b8aa9723c8cdfaf8a"
     ]
    },
    "executionInfo": {
     "elapsed": 6957,
     "status": "ok",
     "timestamp": 1759075605460,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "HxzPgPHnEwPN",
    "outputId": "ff9a276d-b2c8-49ab-c8f4-6ef9a1b10316"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8931bd168545e9ba2de5660893ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454b8c1d0e0c4d94a0e18f0204d840e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9436e720bdf145cbbbeba905cca109f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b7b5a8becd459d9dbe2ba4f2ec3538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08816bff273e445e9626c91d599044fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45ecd6af8b44638a25a422f35206f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2016db24575549abae9411304ffb9a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузма модели\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658903b-1d24-4464-b9cd-afb640ce393b",
   "metadata": {
    "id": "6658903b-1d24-4464-b9cd-afb640ce393b"
   },
   "source": [
    "### Подготовка инструктивного датасета d0rj/alpaca-cleaned-ru для обучения базовой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8caef0-ded4-4033-a159-f35d9206254a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "292285faf8bf4241bff83be1f5dc4cc9",
      "de6d079da6d744a2aebba97aa5862647",
      "352d023574d44e6088468317693f555f",
      "db1623b44b344bb184a12e626bbff60e",
      "546dcfb4dc894f6f8f970f6edf92d2fa",
      "3beaffcc185a445e99cb105cc00ddcfb",
      "f46593328da84fd6b7f06646f335538c",
      "ee8f188a2f7c41fab484344e7d026939",
      "d7764c3c52a343a5b90490b5dfbea6bf",
      "872bae95277641d097b3a94f5c6e14e6",
      "194631fb0a0448e69f973919113cce55",
      "beddcb60b4c840a8be12d4374ea77c7a",
      "406c943a18d54263a35cb929694d73e5",
      "666c732bb1c94dcf91ad5e4a66a52030",
      "50ba0edef2e54ce18ea92abb1304b04c",
      "614aec4e87e14fe3a28c71074960b8eb",
      "c3e8a47103e449f790e951b142584111",
      "d25e94f0a20349e78e338577c46777bf",
      "11a78787c1dc4dd0b61501c9849cfa5a",
      "98a03185723840c3ba0539dcf700659c",
      "d3fa72997a3f44ef8ea588fa81111018",
      "92d7a4ad079448e7b4964685d86d4aa8",
      "a0644bccb49b442488f9602d601d8564",
      "cf84e9b7c6854d77b260517475459280",
      "be67978fd4b74af2aea33a0a03b291a0",
      "4ad87861b47c44bb8461b8ffabe53bf0",
      "9fb82e1c319544c09a31bf3209b8933b",
      "76039f08bdd34b38a0d1cc9a9ddf12dd",
      "75f7abee241b46cc8065684b5886c98f",
      "57d1961513e94c708da1f7d1a8c258c0",
      "2105bfa9dbf541d5a694d1c7d6cf6602",
      "800e0765b1de4d82b299d5138abcff44",
      "e11dd9d60b984ee9b6d0eb60068c67c8"
     ]
    },
    "executionInfo": {
     "elapsed": 2564,
     "status": "ok",
     "timestamp": 1759075617691,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "7a8caef0-ded4-4033-a159-f35d9206254a",
    "outputId": "ebc7e47b-a189-49cc-ac9b-f579e98c2d3a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292285faf8bf4241bff83be1f5dc4cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beddcb60b4c840a8be12d4374ea77c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-c503683bee003a(…):   0%|          | 0.00/36.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0644bccb49b442488f9602d601d8564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "ds = load_dataset(\"d0rj/alpaca-cleaned-ru\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f9226-7ac3-4204-b5ea-f285c5ceac3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6187,
     "status": "ok",
     "timestamp": 1759074432950,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "f24f9226-7ac3-4204-b5ea-f285c5ceac3f",
    "outputId": "3054e4bc-219b-4c19-fc49-70631dd8c140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Примерный размер датасета в токенах: 5,839,049\n",
      "Примерный размер в MB: 73.0 MB\n",
      "Мин. длина: 60 символов\n",
      "Макс. длина: 5,053 символов\n",
      "Медиана: 630 символов\n",
      "Общее количество слов: 5,839,049\n",
      "Среднее количество слов: 113\n",
      "Рекомендуемое количество эпох: 1.7\n"
     ]
    }
   ],
   "source": [
    "# Проведем анализ датасета\n",
    "texts_for_analysis = []\n",
    "for example in ds:\n",
    "    user_part = example[\"instruction\"]\n",
    "    if example[\"input\"].strip():\n",
    "        user_part += \"\\n\" + example[\"input\"]\n",
    "    full_text = f\"### Инструкция:\\n{user_part}\\n\\n### Ответ:\\n{example['output']}\"\n",
    "    texts_for_analysis.append(full_text)\n",
    "\n",
    "# Используем функцию из Части 1.\n",
    "total_tokens = pretraining_analysis(texts_for_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542e1e18-106b-4766-949b-ba91746f46b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "76e24247d9e34d0588b6a17386abed7f",
      "ae7db90ed9a14b5d82be6a48d6a82a14",
      "8bf41130ba80408984b64b499ff55d86",
      "9867032295c7467e94f3831059c465aa",
      "cd9e8c7c211d40ac84d7796d98ee57f1",
      "4d210e55e695406684f0e00b08476fad",
      "6f64fe0be3a54aa6ad8dfedb91eae02b",
      "ed13b6ba5e3349ba9d503f7d09cc918f",
      "b0327efbf7ce488589df70a6f519de41",
      "4cd25a77e10e4243955f41e12de46bd3",
      "dda7b283f2a2443181bb1aaea8dc7709"
     ]
    },
    "executionInfo": {
     "elapsed": 4097,
     "status": "ok",
     "timestamp": 1759075630573,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "542e1e18-106b-4766-949b-ba91746f46b1",
    "outputId": "6499281d-37e4-4733-aa36-8e0850ceca47",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e24247d9e34d0588b6a17386abed7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Форматирование\n",
    "def to_chat_format(example):\n",
    "    user = example[\"instruction\"]\n",
    "    if example[\"input\"].strip():\n",
    "        user += \"\\n\" + example[\"input\"]\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# Применяем форматирование\n",
    "dataset = ds.map(to_chat_format, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c399db-4e27-435f-9630-e491de6dd9b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1759075634782,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "45c399db-4e27-435f-9630-e491de6dd9b7",
    "outputId": "caf2d690-cc84-48c5-ee41-fb352443b7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 49172 примеров\n",
      "Val:   2588 примеров\n"
     ]
    }
   ],
   "source": [
    "# Разделение на тренировочную и валидационную выборки (95% / 5%)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds = dataset[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train_ds)} примеров\")\n",
    "print(f\"Val:   {len(val_ds)} примеров\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7714d0-7d7a-4399-9284-dd68472f6b33",
   "metadata": {
    "id": "7d7714d0-7d7a-4399-9284-dd68472f6b33"
   },
   "source": [
    "### Настройка SFT-обучения. Обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oGf__MtBFClX",
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1759075660549,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "oGf__MtBFClX"
   },
   "outputs": [],
   "source": [
    "# Сокращаем датасет до 10% для быстрого обучения\n",
    "train_ds = train_ds.shuffle(seed=42).select(range(int(len(train_ds) * 0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hTS2Oa8GJrhV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "437d6d88c6e848b48c4b865cb9d3528b",
      "19830ed957444884b59c6cb0a49caedb",
      "219a28e320074c6b82b5dbc747bc64c9",
      "e5e6e89263a2429e8e956398aae2d06d",
      "9c4b51a9d18f458683aa0af10fc9541c",
      "8917406ef32340658832081e6d04fb25",
      "ec723e1feb6747d5a2fecfd81d16b5e1",
      "5f86e198a8fd47da944dd72c2f45a8dc",
      "0f10f4e626784bbabf2652600fac7331",
      "d08287e5671a4542b4cff2168730aa2d",
      "41a937d60de145fab1478fd2328e0b02",
      "f1f85c7086bd4054920daf1491142ce5",
      "464e5f6563fa493eb0a5c96436226783",
      "062d65f8cfab49198c5a4a68ff7a95dd",
      "92118f7d4c804e7f96be89dfbbdb3d3d",
      "dbc93adf458c47fb99cbb5257786659a",
      "0fb19f9373084d229749ea7cd0b47b68",
      "39ba36b03dc345a3b7ce1ddf483cf438",
      "7fd323f15101497199e3d8d090e6fa89",
      "8df58d80877e47798d359b3183655acd",
      "ae694b25514049bb93cb51c1d36ec6a3",
      "b4a2bce70fa749d591df9cfd0973d113",
      "2b576c3628bf496f87c7015ffde5064b",
      "8dec7d4efe614b139f4c1bf4fa347da9",
      "5c2580c9bba7441782cca4523db421f1",
      "f6bc9d8e712a44bb9940236f03d4adb9",
      "b1dd1809455846cc8a0daa2684c3ec42",
      "65dfa64b23b446aba4fa2a26725edaf7",
      "be428a128f3b422f882c2b010d4958b3",
      "0ce6c939e2a04ce59da3d7a08cbf264b",
      "1a6d06ac427244138bdadd37795137b7",
      "b236e891da34471299f35ffb7a81b388",
      "bec0fa686745489d9cd0cb214ba41f8b"
     ]
    },
    "executionInfo": {
     "elapsed": 858907,
     "status": "ok",
     "timestamp": 1759077785379,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "hTS2Oa8GJrhV",
    "outputId": "d47a16ff-1dce-4f02-b2e0-b8dc9d9579dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437d6d88c6e848b48c4b865cb9d3528b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to eval dataset:   0%|          | 0/2588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f85c7086bd4054920daf1491142ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/2588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b576c3628bf496f87c7015ffde5064b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/2588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='615' max='615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [615/615 14:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.039400</td>\n",
       "      <td>1.587106</td>\n",
       "      <td>1.166818</td>\n",
       "      <td>437746.000000</td>\n",
       "      <td>0.658701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.060600</td>\n",
       "      <td>1.467398</td>\n",
       "      <td>1.171036</td>\n",
       "      <td>879401.000000</td>\n",
       "      <td>0.676760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.281300</td>\n",
       "      <td>1.369188</td>\n",
       "      <td>1.295174</td>\n",
       "      <td>1324237.000000</td>\n",
       "      <td>0.690146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# Функция форматирования для SFTTrainer\n",
    "def formatting_func(example):\n",
    "    messages = example[\"messages\"]\n",
    "    # Применяем шаблон → строка\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    # Обрезаем до 256 токенов\n",
    "    tokens = tokenizer(text, truncation=True, max_length=256, add_special_tokens=False)[\"input_ids\"]\n",
    "    truncated_text = tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "    return truncated_text\n",
    "\n",
    "# Аргументы обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\",\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    formatting_func=formatting_func\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "trainer.train()\n",
    "\n",
    "# Сохранение\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "model.save_pretrained(\"./checkpoints/sft_model\")\n",
    "tokenizer.save_pretrained(\"./checkpoints/sft_tokenizer\")\n",
    "print(\"Модель сохранена в ./checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045f47f-13fa-408e-a39e-078e0b61982b",
   "metadata": {
    "id": "6045f47f-13fa-408e-a39e-078e0b61982b"
   },
   "source": [
    "### Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0XAWg42QNWdO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20537,
     "status": "ok",
     "timestamp": 1759077879263,
     "user": {
      "displayName": "Екатерина Федотова",
      "userId": "14107055361954780468"
     },
     "user_tz": -180
    },
    "id": "0XAWg42QNWdO",
    "outputId": "c8b3ca92-3208-4e64-e0cc-c373fb2d0ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---               ---\n",
      "\n",
      "Model Input 1:\n",
      "сколько планет в нашей солнечной системе?\n",
      "Model Output 1:\n",
      "assistant\n",
      "В нашей солнечной системе 8 планеты. Эти планеты расположены в круговоротной палеодрой с ускоряющей силой, известной как «жимур». Это означает, что планеты движутся вокруг Земли со скоростью около 110,5 единицы в час, а это означает, что они вращаются вокруг Земли примерно 29,5 часов, или 8,5 дня.\n",
      "assistant\n",
      "В нашей солнечной системе 8 планеты. Эти планеты расположены в круговоротной палеодрой с у\n",
      "assistant\n",
      "\n",
      "Model Input 2:\n",
      "расскажи стих\n",
      "Model Output 2:\n",
      "assistant\n",
      "Солнце светит, как светящий свет,\n",
      "Красота природы, которую мы никогда не видели,\n",
      "Деревья растут, а ручьи покачиваются,\n",
      "Величие, которое может возвышаться.\n",
      "\n",
      "Солнце, полное красоты,\n",
      "Величайшая и самая совершенная сущность,\n",
      "Оно, кажется, изображение солнца,\n",
      "Оно, кажется, сияние солнца.\n",
      "\n",
      "Солнце, которое изображение,\n",
      "Оно, которое изображение,\n",
      "Истинный свет, который никогда не умаляется,\n",
      "Красота, которую мы никогда не увидели\n",
      "assistant\n",
      "\n",
      "Model Input 3:\n",
      "когда собирать крыжовник?\n",
      "Model Output 3:\n",
      "assistant\n",
      "Когда собираешь крыжовник, вам потребуется несколько инструментов и материалов:\n",
      "\n",
      "- Трубка: это самый простой и распространенный инструмент, который можно найти в каждом доме. Обычно он вмещает около 12 футов в длину и имеет пяти шагов на длина, что означает, что его можно использовать для сбора крыжовника из 12-15 угодий.\n",
      "- Винтовка: это более сложный инструмент, который обычно используется в стальных домах или домах, где вы собираете крыжовник. Винтовка обычно представляет собой\n",
      "assistant\n",
      "\n",
      "Model Input 4:\n",
      "Как быстро выучить новый язык?\n",
      "Model Output 4:\n",
      "assistant\n",
      "Существует несколько способов быстрого обучения нового языка, в том числе:\n",
      "\n",
      "1. Ознакомьтесь с основными знаниями: начните с основных основных понятий, таких как грамматика, грамматика, связь между словами и семантические понятия.\n",
      "\n",
      "2. Воспитывайте язык: используйте язык в реальных обстоятельствах, используйте язык в интерактивном и практическом процессе и не ограничьте себя только домашними заданиями или тестами.\n",
      "\n",
      "3. Приспособляйтесь к конкретным потребностям: начните с конкретных\n",
      "assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Финальная оценка\n",
    "questions_rus = [\n",
    "    \"сколько планет в нашей солнечной системе?\",\n",
    "    \"расскажи стих\",\n",
    "    \"когда собирать крыжовник?\",\n",
    "    \"Как быстро выучить новый язык?\"\n",
    "]\n",
    "\n",
    "print(\"---               ---\\n\")\n",
    "\n",
    "for i, question in enumerate(questions_rus, 1):\n",
    "    print(f\"Model Input {i}:\")\n",
    "    print(question)\n",
    "\n",
    "    # Формируем сообщение в формате чата\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    # Применяем шаблон чата\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    # Генерация\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # Извлекаем только ответ ассистента (без промпта)\n",
    "    generated_tokens = outputs[0][input_ids.shape[1]:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"Model Output {i}:\")\n",
    "    print(response.strip())\n",
    "    print(\"assistant\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ce3b8-36a2-4b81-88e5-dd7b89f14671",
   "metadata": {},
   "source": [
    "***Вывод по Этапу 2 (SFT — Дообучение на инструкциях)***\n",
    "\n",
    "На втором этапе модель была дообучена на инструктивном датасете (d0rj/alpaca-cleaned-ru). Результаты демонстрируют радикальное улучшение:\n",
    "\n",
    "Модель научилась распознавать и выполнять инструкции — она корректно отвечает на вопросы, используя формат assistant, как и было задумано.\n",
    "Ответы структурированы и информативны: Например - на вопрос «сколько планет в нашей солнечной системе?» — даёт точный ответ (8) и добавляет дополнительную информацию (вращение вокруг Земли, термин «жимур» — возможно, опечатка или артефакт обучения).\n",
    "На запрос «расскажи стих» — генерирует стихотворение с рифмой, размером и тематическим содержанием. \n",
    "\n",
    "Улучшение модели: Провести более тщательную валидацию SFT-данных, чтобы избежать артефактов в ответах (например, «жимур»)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6fb91-8566-4f43-8073-d278607e10b7",
   "metadata": {},
   "source": [
    "***Общий вывод проекта***\n",
    "\n",
    "Проект успешно реализовал два ключевых этапа обучения LLM:\n",
    "\n",
    "Pretrain — дал модели глубокое понимание русского языка, особенно в литературном стиле, но не научил её взаимодействовать с пользователем.\n",
    "\n",
    "SFT — преобразовал модель в интеллектуального ассистента, способного понимать инструкции, отвечать на вопросы и генерировать контент по запросу.\n",
    "\n",
    "Таким образом, комбинация предобучения на качественном корпусе и последующего дообучения на инструктивных данных является эффективной стратегией для создания языковой модели, ориентированной на практическое применение. Модель после SFT может быть использована в диалоговых системах, помощниках, образовательных приложениях и других сценариях, требующих понимания запросов и генерации целенаправленного ответа."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2024-05-20T16:58:58.258Z"
   },
   {
    "duration": 1243,
    "start_time": "2024-05-20T17:08:49.040Z"
   },
   {
    "duration": 52,
    "start_time": "2024-05-20T17:09:52.259Z"
   },
   {
    "duration": 50,
    "start_time": "2024-05-20T17:12:03.114Z"
   },
   {
    "duration": 14126,
    "start_time": "2024-05-20T17:13:13.717Z"
   },
   {
    "duration": 6615,
    "start_time": "2024-05-20T17:20:33.618Z"
   },
   {
    "duration": 16,
    "start_time": "2024-05-20T17:20:44.195Z"
   },
   {
    "duration": 94,
    "start_time": "2024-05-20T17:21:24.097Z"
   },
   {
    "duration": 535,
    "start_time": "2024-05-20T17:22:10.688Z"
   },
   {
    "duration": 254,
    "start_time": "2024-05-20T17:22:16.653Z"
   },
   {
    "duration": 181,
    "start_time": "2024-05-20T17:23:36.267Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-20T17:30:56.848Z"
   },
   {
    "duration": 799,
    "start_time": "2024-05-20T17:31:16.403Z"
   },
   {
    "duration": 4146,
    "start_time": "2024-05-20T17:34:37.856Z"
   },
   {
    "duration": 1553,
    "start_time": "2024-05-21T07:37:55.203Z"
   },
   {
    "duration": 19743,
    "start_time": "2024-05-21T07:38:03.751Z"
   },
   {
    "duration": 9714,
    "start_time": "2024-05-21T07:38:26.688Z"
   },
   {
    "duration": 17,
    "start_time": "2024-05-21T07:38:41.274Z"
   },
   {
    "duration": 733,
    "start_time": "2024-05-21T07:44:11.971Z"
   },
   {
    "duration": 46,
    "start_time": "2024-05-21T07:45:58.524Z"
   },
   {
    "duration": 1451,
    "start_time": "2024-05-21T07:46:24.964Z"
   },
   {
    "duration": 5262,
    "start_time": "2024-05-21T07:50:11.442Z"
   },
   {
    "duration": 122,
    "start_time": "2024-05-21T08:00:00.656Z"
   },
   {
    "duration": 16,
    "start_time": "2024-05-21T08:00:05.555Z"
   },
   {
    "duration": 24,
    "start_time": "2024-05-21T08:06:36.434Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-21T08:07:14.423Z"
   },
   {
    "duration": 65,
    "start_time": "2024-05-21T08:07:34.824Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-21T08:07:42.600Z"
   },
   {
    "duration": 17,
    "start_time": "2024-05-21T08:14:02.077Z"
   },
   {
    "duration": 589,
    "start_time": "2024-05-21T08:15:59.218Z"
   },
   {
    "duration": 4045,
    "start_time": "2024-05-21T08:17:03.760Z"
   },
   {
    "duration": 314,
    "start_time": "2024-05-21T08:21:00.789Z"
   },
   {
    "duration": 1131,
    "start_time": "2024-05-21T08:21:23.084Z"
   },
   {
    "duration": 65,
    "start_time": "2024-05-21T08:27:16.573Z"
   },
   {
    "duration": 25230,
    "start_time": "2024-05-21T08:29:28.888Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-21T09:02:15.096Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-21T09:52:16.719Z"
   },
   {
    "duration": 494,
    "start_time": "2024-05-21T09:52:38.899Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-21T09:53:28.412Z"
   },
   {
    "duration": 4096,
    "start_time": "2024-05-21T09:53:32.091Z"
   },
   {
    "duration": 149,
    "start_time": "2024-05-21T09:55:07.993Z"
   },
   {
    "duration": 90,
    "start_time": "2024-05-21T09:55:33.349Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-21T09:55:51.261Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-21T09:56:54.437Z"
   },
   {
    "duration": 1250,
    "start_time": "2024-05-21T09:57:02.043Z"
   },
   {
    "duration": 875,
    "start_time": "2024-05-21T09:58:17.427Z"
   },
   {
    "duration": 488,
    "start_time": "2024-05-21T09:58:38.139Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-21T10:00:53.888Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-21T10:02:03.264Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-21T10:02:57.348Z"
   },
   {
    "duration": 772,
    "start_time": "2024-05-21T10:03:38.470Z"
   },
   {
    "duration": 642,
    "start_time": "2024-05-21T10:08:42.784Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-21T10:10:40.360Z"
   },
   {
    "duration": 1960,
    "start_time": "2024-05-21T10:18:52.293Z"
   },
   {
    "duration": 1649,
    "start_time": "2024-05-21T10:19:11.079Z"
   },
   {
    "duration": 1494,
    "start_time": "2024-05-21T10:19:24.268Z"
   },
   {
    "duration": 69,
    "start_time": "2024-05-21T10:24:12.636Z"
   },
   {
    "duration": 90,
    "start_time": "2024-05-21T10:24:31.580Z"
   },
   {
    "duration": 852,
    "start_time": "2024-05-21T10:28:38.208Z"
   },
   {
    "duration": 961,
    "start_time": "2024-05-21T10:29:00.520Z"
   },
   {
    "duration": 1668,
    "start_time": "2024-05-21T10:29:50.232Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-21T11:51:15.672Z"
   },
   {
    "duration": 140,
    "start_time": "2024-05-21T12:00:00.431Z"
   },
   {
    "duration": 100,
    "start_time": "2024-05-21T12:01:22.095Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-21T12:02:49.846Z"
   },
   {
    "duration": 102,
    "start_time": "2024-05-21T12:02:53.618Z"
   },
   {
    "duration": 2702,
    "start_time": "2024-05-21T12:03:57.501Z"
   },
   {
    "duration": 599,
    "start_time": "2024-05-21T12:04:35.219Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-21T12:05:18.103Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-21T12:05:59.330Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-21T12:06:12.917Z"
   },
   {
    "duration": 97,
    "start_time": "2024-05-21T12:07:02.479Z"
   },
   {
    "duration": 1780,
    "start_time": "2024-05-21T12:07:47.213Z"
   },
   {
    "duration": 337,
    "start_time": "2024-05-21T12:08:10.474Z"
   },
   {
    "duration": 1445,
    "start_time": "2024-05-21T12:12:41.002Z"
   },
   {
    "duration": 16349,
    "start_time": "2024-05-21T12:12:42.449Z"
   },
   {
    "duration": 10098,
    "start_time": "2024-05-21T12:12:58.800Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-21T12:13:08.901Z"
   },
   {
    "duration": 797,
    "start_time": "2024-05-21T12:13:08.923Z"
   },
   {
    "duration": 508,
    "start_time": "2024-05-21T12:13:09.722Z"
   },
   {
    "duration": 66,
    "start_time": "2024-05-21T12:13:10.232Z"
   },
   {
    "duration": 1329,
    "start_time": "2024-05-21T12:13:10.300Z"
   },
   {
    "duration": 6399,
    "start_time": "2024-05-21T12:13:11.630Z"
   },
   {
    "duration": 713,
    "start_time": "2024-05-21T12:13:18.094Z"
   },
   {
    "duration": 1408,
    "start_time": "2024-05-21T12:13:18.810Z"
   },
   {
    "duration": 5332,
    "start_time": "2024-05-21T12:13:20.220Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-21T12:13:25.554Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-21T12:13:25.559Z"
   },
   {
    "duration": 353,
    "start_time": "2024-05-21T12:13:25.574Z"
   },
   {
    "duration": 109,
    "start_time": "2024-05-21T12:15:30.894Z"
   },
   {
    "duration": 1731,
    "start_time": "2024-05-21T12:22:18.309Z"
   },
   {
    "duration": 101,
    "start_time": "2024-05-21T12:22:23.736Z"
   },
   {
    "duration": 442,
    "start_time": "2024-05-21T12:22:51.170Z"
   },
   {
    "duration": 34,
    "start_time": "2024-05-21T12:56:49.021Z"
   },
   {
    "duration": 446,
    "start_time": "2024-05-21T12:57:41.579Z"
   },
   {
    "duration": 433,
    "start_time": "2024-05-21T13:01:15.279Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-21T13:01:57.534Z"
   },
   {
    "duration": 1224,
    "start_time": "2024-05-21T13:05:27.777Z"
   },
   {
    "duration": 381,
    "start_time": "2024-05-21T13:06:03.839Z"
   },
   {
    "duration": 498,
    "start_time": "2024-05-21T13:13:37.104Z"
   },
   {
    "duration": 424,
    "start_time": "2024-05-21T13:13:42.695Z"
   },
   {
    "duration": 103,
    "start_time": "2024-05-21T13:21:38.390Z"
   },
   {
    "duration": 3281,
    "start_time": "2024-05-21T13:22:11.421Z"
   },
   {
    "duration": 1627,
    "start_time": "2024-05-21T13:22:51.483Z"
   },
   {
    "duration": 404,
    "start_time": "2024-05-21T13:45:38.601Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-21T13:46:20.919Z"
   },
   {
    "duration": 5344,
    "start_time": "2024-05-21T13:47:01.082Z"
   },
   {
    "duration": 3977,
    "start_time": "2024-05-21T13:48:27.929Z"
   },
   {
    "duration": 3275,
    "start_time": "2024-05-21T13:50:55.602Z"
   },
   {
    "duration": 3165,
    "start_time": "2024-05-21T13:51:07.934Z"
   },
   {
    "duration": 3042,
    "start_time": "2024-05-21T13:52:11.516Z"
   },
   {
    "duration": 2893,
    "start_time": "2024-05-21T13:52:30.660Z"
   },
   {
    "duration": 2423,
    "start_time": "2024-05-21T13:53:55.784Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-21T13:55:42.817Z"
   },
   {
    "duration": 2248,
    "start_time": "2024-05-21T13:59:03.516Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-21T13:59:09.175Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-21T14:01:25.934Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-21T14:02:45.705Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-21T14:02:57.071Z"
   },
   {
    "duration": 68,
    "start_time": "2024-05-21T14:11:25.744Z"
   },
   {
    "duration": 1387,
    "start_time": "2024-05-22T08:06:56.559Z"
   },
   {
    "duration": 14339,
    "start_time": "2024-05-22T08:07:01.449Z"
   },
   {
    "duration": 7829,
    "start_time": "2024-05-22T08:07:18.833Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-22T08:07:30.903Z"
   },
   {
    "duration": 573,
    "start_time": "2024-05-22T08:07:41.296Z"
   },
   {
    "duration": 40,
    "start_time": "2024-05-22T08:07:54.112Z"
   },
   {
    "duration": 1049,
    "start_time": "2024-05-22T08:08:00.522Z"
   },
   {
    "duration": 4816,
    "start_time": "2024-05-22T08:08:26.231Z"
   },
   {
    "duration": 535,
    "start_time": "2024-05-22T08:08:34.421Z"
   },
   {
    "duration": 983,
    "start_time": "2024-05-22T08:08:52.486Z"
   },
   {
    "duration": 3883,
    "start_time": "2024-05-22T08:09:20.439Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T08:10:49.603Z"
   },
   {
    "duration": 1561,
    "start_time": "2024-05-22T08:10:54.299Z"
   },
   {
    "duration": 395,
    "start_time": "2024-05-22T08:11:00.663Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-22T08:11:10.478Z"
   },
   {
    "duration": 765,
    "start_time": "2024-05-22T08:11:33.006Z"
   },
   {
    "duration": 405,
    "start_time": "2024-05-22T08:11:59.510Z"
   },
   {
    "duration": 366,
    "start_time": "2024-05-22T08:12:08.506Z"
   },
   {
    "duration": 2716,
    "start_time": "2024-05-22T08:12:29.736Z"
   },
   {
    "duration": 257,
    "start_time": "2024-05-22T08:14:18.499Z"
   },
   {
    "duration": 4171,
    "start_time": "2024-05-22T08:14:36.791Z"
   },
   {
    "duration": 54,
    "start_time": "2024-05-22T08:20:20.372Z"
   },
   {
    "duration": 56,
    "start_time": "2024-05-22T08:20:29.207Z"
   },
   {
    "duration": 124,
    "start_time": "2024-05-22T08:21:05.077Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-22T08:21:16.118Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-22T08:21:34.885Z"
   },
   {
    "duration": 3111,
    "start_time": "2024-05-22T08:23:21.283Z"
   },
   {
    "duration": 826,
    "start_time": "2024-05-22T08:41:01.522Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-22T09:27:59.097Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-22T09:28:16.758Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-22T09:28:19.714Z"
   },
   {
    "duration": 2235,
    "start_time": "2024-05-22T09:32:37.093Z"
   },
   {
    "duration": 2351,
    "start_time": "2024-05-22T09:33:22.160Z"
   },
   {
    "duration": 2411,
    "start_time": "2024-05-22T09:34:06.424Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-22T09:38:06.004Z"
   },
   {
    "duration": 60,
    "start_time": "2024-05-22T09:41:52.056Z"
   },
   {
    "duration": 16,
    "start_time": "2024-05-22T09:42:07.066Z"
   },
   {
    "duration": 16,
    "start_time": "2024-05-22T09:42:27.543Z"
   },
   {
    "duration": 12,
    "start_time": "2024-05-22T09:43:08.267Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-22T09:43:20.334Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-22T09:46:41.388Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T09:46:51.177Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-22T09:47:46.308Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T09:48:02.658Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-22T09:50:24.227Z"
   },
   {
    "duration": 826,
    "start_time": "2024-05-22T09:50:52.248Z"
   },
   {
    "duration": 149,
    "start_time": "2024-05-22T09:52:53.919Z"
   },
   {
    "duration": 193,
    "start_time": "2024-05-22T09:56:22.611Z"
   },
   {
    "duration": 150,
    "start_time": "2024-05-22T09:57:12.681Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-22T09:58:57.947Z"
   },
   {
    "duration": 2440,
    "start_time": "2024-05-22T09:59:19.909Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-22T09:59:59.020Z"
   },
   {
    "duration": 211,
    "start_time": "2024-05-22T10:00:05.478Z"
   },
   {
    "duration": 120,
    "start_time": "2024-05-22T10:00:22.472Z"
   },
   {
    "duration": 500,
    "start_time": "2024-05-22T10:01:08.476Z"
   },
   {
    "duration": 150,
    "start_time": "2024-05-22T10:01:11.984Z"
   },
   {
    "duration": 172,
    "start_time": "2024-05-22T10:01:30.441Z"
   },
   {
    "duration": 152,
    "start_time": "2024-05-22T10:01:38.790Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-22T10:03:04.155Z"
   },
   {
    "duration": 2188,
    "start_time": "2024-05-22T10:03:18.458Z"
   },
   {
    "duration": 707,
    "start_time": "2024-05-22T10:03:25.198Z"
   },
   {
    "duration": 2493,
    "start_time": "2024-05-22T10:23:57.667Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:26:54.998Z"
   },
   {
    "duration": 58,
    "start_time": "2024-05-22T10:29:26.883Z"
   },
   {
    "duration": 52,
    "start_time": "2024-05-22T10:29:43.937Z"
   },
   {
    "duration": 2384,
    "start_time": "2024-05-22T10:29:52.673Z"
   },
   {
    "duration": 842,
    "start_time": "2024-05-22T10:30:12.685Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:30:57.616Z"
   },
   {
    "duration": 592,
    "start_time": "2024-05-22T10:31:01.618Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:32:00.733Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-22T10:32:03.045Z"
   },
   {
    "duration": 1895,
    "start_time": "2024-05-22T10:32:19.253Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:32:27.522Z"
   },
   {
    "duration": 551,
    "start_time": "2024-05-22T10:32:31.717Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-22T10:33:56.809Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-22T10:34:39.244Z"
   },
   {
    "duration": 706,
    "start_time": "2024-05-22T10:34:48.713Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:35:11.253Z"
   },
   {
    "duration": 1712,
    "start_time": "2024-05-22T10:35:26.633Z"
   },
   {
    "duration": 1543,
    "start_time": "2024-05-22T10:35:32.523Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T10:36:46.301Z"
   },
   {
    "duration": 785,
    "start_time": "2024-05-22T10:37:20.254Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:47:06.014Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-22T10:49:36.651Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-22T10:49:56.360Z"
   },
   {
    "duration": 121,
    "start_time": "2024-05-22T10:50:01.158Z"
   },
   {
    "duration": 88,
    "start_time": "2024-05-22T10:50:34.030Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-22T10:50:40.741Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-22T10:51:03.142Z"
   },
   {
    "duration": 25,
    "start_time": "2024-05-22T10:51:05.521Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T10:51:22.630Z"
   },
   {
    "duration": 102,
    "start_time": "2024-05-22T10:51:24.465Z"
   },
   {
    "duration": 1672,
    "start_time": "2024-05-22T10:55:42.013Z"
   },
   {
    "duration": 1518,
    "start_time": "2024-05-22T10:56:00.974Z"
   },
   {
    "duration": 128,
    "start_time": "2024-05-22T11:01:27.125Z"
   },
   {
    "duration": 441,
    "start_time": "2024-05-22T11:01:43.348Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T11:01:45.764Z"
   },
   {
    "duration": 162,
    "start_time": "2024-05-22T11:01:53.911Z"
   },
   {
    "duration": 437,
    "start_time": "2024-05-22T11:01:57.926Z"
   },
   {
    "duration": 114,
    "start_time": "2024-05-22T11:02:03.686Z"
   },
   {
    "duration": 1355,
    "start_time": "2024-05-22T11:02:47.204Z"
   },
   {
    "duration": 1528,
    "start_time": "2024-05-22T11:40:10.767Z"
   },
   {
    "duration": 1155,
    "start_time": "2024-05-22T11:55:11.069Z"
   },
   {
    "duration": 14840,
    "start_time": "2024-05-22T11:55:12.225Z"
   },
   {
    "duration": 8711,
    "start_time": "2024-05-22T11:55:27.068Z"
   },
   {
    "duration": 76,
    "start_time": "2024-05-22T11:55:35.781Z"
   },
   {
    "duration": 690,
    "start_time": "2024-05-22T11:55:35.858Z"
   },
   {
    "duration": 34,
    "start_time": "2024-05-22T11:55:36.550Z"
   },
   {
    "duration": 1182,
    "start_time": "2024-05-22T11:55:36.585Z"
   },
   {
    "duration": 4382,
    "start_time": "2024-05-22T11:55:37.768Z"
   },
   {
    "duration": 503,
    "start_time": "2024-05-22T11:55:42.151Z"
   },
   {
    "duration": 1004,
    "start_time": "2024-05-22T11:55:42.658Z"
   },
   {
    "duration": 4032,
    "start_time": "2024-05-22T11:55:43.663Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T11:55:47.697Z"
   },
   {
    "duration": 1755,
    "start_time": "2024-05-22T11:55:47.702Z"
   },
   {
    "duration": 390,
    "start_time": "2024-05-22T11:55:49.459Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-22T11:55:49.851Z"
   },
   {
    "duration": 974,
    "start_time": "2024-05-22T11:55:49.873Z"
   },
   {
    "duration": 367,
    "start_time": "2024-05-22T11:55:50.848Z"
   },
   {
    "duration": 365,
    "start_time": "2024-05-22T11:55:51.217Z"
   },
   {
    "duration": 2971,
    "start_time": "2024-05-22T11:55:51.583Z"
   },
   {
    "duration": 302,
    "start_time": "2024-05-22T11:55:54.556Z"
   },
   {
    "duration": 4040,
    "start_time": "2024-05-22T11:55:54.860Z"
   },
   {
    "duration": 3429,
    "start_time": "2024-05-22T11:55:58.901Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-22T11:56:02.332Z"
   },
   {
    "duration": 896,
    "start_time": "2024-05-22T11:56:02.345Z"
   },
   {
    "duration": 880,
    "start_time": "2024-05-22T11:56:03.243Z"
   },
   {
    "duration": 194,
    "start_time": "2024-05-22T12:00:52.262Z"
   },
   {
    "duration": 1166,
    "start_time": "2024-05-22T12:01:06.075Z"
   },
   {
    "duration": 14437,
    "start_time": "2024-05-22T12:01:07.243Z"
   },
   {
    "duration": 7777,
    "start_time": "2024-05-22T12:01:21.682Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-22T12:01:29.461Z"
   },
   {
    "duration": 499,
    "start_time": "2024-05-22T12:01:29.477Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-22T12:01:29.978Z"
   },
   {
    "duration": 1117,
    "start_time": "2024-05-22T12:01:30.046Z"
   },
   {
    "duration": 5381,
    "start_time": "2024-05-22T12:01:31.165Z"
   },
   {
    "duration": 604,
    "start_time": "2024-05-22T12:01:36.547Z"
   },
   {
    "duration": 1216,
    "start_time": "2024-05-22T12:01:37.154Z"
   },
   {
    "duration": 4476,
    "start_time": "2024-05-22T12:01:38.372Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-22T12:01:42.850Z"
   },
   {
    "duration": 1669,
    "start_time": "2024-05-22T12:01:42.855Z"
   },
   {
    "duration": 371,
    "start_time": "2024-05-22T12:01:44.526Z"
   },
   {
    "duration": 23,
    "start_time": "2024-05-22T12:01:44.945Z"
   },
   {
    "duration": 907,
    "start_time": "2024-05-22T12:01:44.969Z"
   },
   {
    "duration": 474,
    "start_time": "2024-05-22T12:01:45.878Z"
   },
   {
    "duration": 350,
    "start_time": "2024-05-22T12:01:46.353Z"
   },
   {
    "duration": 2603,
    "start_time": "2024-05-22T12:01:46.746Z"
   },
   {
    "duration": 331,
    "start_time": "2024-05-22T12:01:49.351Z"
   },
   {
    "duration": 4275,
    "start_time": "2024-05-22T12:01:49.684Z"
   },
   {
    "duration": 3474,
    "start_time": "2024-05-22T12:01:53.960Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-22T12:01:57.436Z"
   },
   {
    "duration": 990,
    "start_time": "2024-05-22T12:01:57.452Z"
   },
   {
    "duration": 1044,
    "start_time": "2024-05-22T12:01:58.445Z"
   },
   {
    "duration": 85,
    "start_time": "2024-05-23T13:51:40.869Z"
   },
   {
    "duration": 1296,
    "start_time": "2024-05-23T13:53:55.258Z"
   },
   {
    "duration": 14466,
    "start_time": "2024-05-23T13:54:00.163Z"
   },
   {
    "duration": 7338,
    "start_time": "2024-05-23T13:54:16.699Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-23T13:54:27.203Z"
   },
   {
    "duration": 360,
    "start_time": "2024-05-23T13:54:31.158Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-23T13:54:34.693Z"
   },
   {
    "duration": 3872,
    "start_time": "2024-05-23T13:54:38.529Z"
   },
   {
    "duration": 1396,
    "start_time": "2024-05-23T18:31:35.614Z"
   },
   {
    "duration": 14775,
    "start_time": "2024-05-23T18:31:37.012Z"
   },
   {
    "duration": 8094,
    "start_time": "2024-05-23T18:31:51.790Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-23T18:31:59.887Z"
   },
   {
    "duration": 420,
    "start_time": "2024-05-23T18:31:59.970Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-23T18:32:00.391Z"
   },
   {
    "duration": 4269,
    "start_time": "2024-05-23T18:32:00.402Z"
   },
   {
    "duration": 4423,
    "start_time": "2024-05-23T18:32:04.673Z"
   },
   {
    "duration": 583,
    "start_time": "2024-05-23T18:32:09.099Z"
   },
   {
    "duration": 1218,
    "start_time": "2024-05-23T18:32:09.685Z"
   },
   {
    "duration": 5172,
    "start_time": "2024-05-23T18:32:10.904Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-23T18:32:16.078Z"
   },
   {
    "duration": 1474,
    "start_time": "2024-05-23T18:32:16.083Z"
   },
   {
    "duration": 407,
    "start_time": "2024-05-23T18:32:17.570Z"
   },
   {
    "duration": 20,
    "start_time": "2024-05-23T18:32:17.979Z"
   },
   {
    "duration": 982,
    "start_time": "2024-05-23T18:32:18.001Z"
   },
   {
    "duration": 401,
    "start_time": "2024-05-23T18:32:18.985Z"
   },
   {
    "duration": 400,
    "start_time": "2024-05-23T18:32:19.388Z"
   },
   {
    "duration": 2901,
    "start_time": "2024-05-23T18:32:19.790Z"
   },
   {
    "duration": 312,
    "start_time": "2024-05-23T18:32:22.693Z"
   },
   {
    "duration": 4564,
    "start_time": "2024-05-23T18:32:23.007Z"
   },
   {
    "duration": 3661,
    "start_time": "2024-05-23T18:32:27.573Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-23T18:32:31.236Z"
   },
   {
    "duration": 1271,
    "start_time": "2024-05-23T18:32:31.246Z"
   },
   {
    "duration": 1076,
    "start_time": "2024-05-23T18:32:32.519Z"
   }
  ],
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
